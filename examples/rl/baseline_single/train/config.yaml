smarts:
  # Environment
  head: False # If True, enables Envision display.
  sumo_gui: False # If True, enables sumo-gui display.
  num_stack: 3 # Number of frames to stack as input to policy network.
  seed: 42
  agent_locator: inference:contrib-agent-v0
  env_id: smarts.env:platoon-v0  
  scenarios: 
    - "no_traffic_agents_1"

  # PPO algorithm
  n_steps: 512
  batch_size: 128

  # Training over all scenarios
  epochs: 1 # Number of training loops.

  # Training per scenario
  # train_steps: 4_096
  # checkpoint_freq: 4_096
  train_steps: 2_000_000
  checkpoint_freq: 32_768 # Save a model every checkpoint_freq calls to env.step().
  eval_freq: 32_768 # Evaluate the trained model every eval_freq steps and save the best model.
  eval_eps: 30 # Number of evaluation epsiodes.
